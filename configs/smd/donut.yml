experiment: donut
model_params:
  hidden_dims: [100, 100]
  latent_dim: 20
  mask_prob: 0.01
epochs: 100
transforms:
  train:
    window:
      args:
        window_size: 10
  test:
    window:
      args:
        window_size: 10
  seq_len: 10  # Based on the window size of the training data
run_params:
  scheduler:
    class: 'torch.optim.lr_scheduler.MultiStepLR'
    args:
      milestones: [20]
      gamma: 0.1
detector_params:
  num_mc_samples: 2
